{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47c64638-5c9a-47ca-9a67-adf8a38080a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios encontrados: ['marcelo', 'rostro_0.jpg', 'rostro_1.jpg', 'rostro_10.jpg', 'rostro_100.jpg', 'rostro_101.jpg', 'rostro_102.jpg', 'rostro_103.jpg', 'rostro_104.jpg', 'rostro_105.jpg', 'rostro_106.jpg', 'rostro_107.jpg', 'rostro_108.jpg', 'rostro_109.jpg', 'rostro_11.jpg', 'rostro_110.jpg', 'rostro_111.jpg', 'rostro_112.jpg', 'rostro_113.jpg', 'rostro_114.jpg', 'rostro_115.jpg', 'rostro_116.jpg', 'rostro_117.jpg', 'rostro_118.jpg', 'rostro_119.jpg', 'rostro_12.jpg', 'rostro_120.jpg', 'rostro_121.jpg', 'rostro_122.jpg', 'rostro_123.jpg', 'rostro_124.jpg', 'rostro_125.jpg', 'rostro_126.jpg', 'rostro_127.jpg', 'rostro_128.jpg', 'rostro_129.jpg', 'rostro_13.jpg', 'rostro_130.jpg', 'rostro_131.jpg', 'rostro_132.jpg', 'rostro_133.jpg', 'rostro_134.jpg', 'rostro_135.jpg', 'rostro_136.jpg', 'rostro_137.jpg', 'rostro_138.jpg', 'rostro_139.jpg', 'rostro_14.jpg', 'rostro_140.jpg', 'rostro_141.jpg', 'rostro_142.jpg', 'rostro_143.jpg', 'rostro_144.jpg', 'rostro_145.jpg', 'rostro_146.jpg', 'rostro_147.jpg', 'rostro_148.jpg', 'rostro_149.jpg', 'rostro_15.jpg', 'rostro_150.jpg', 'rostro_151.jpg', 'rostro_152.jpg', 'rostro_153.jpg', 'rostro_154.jpg', 'rostro_155.jpg', 'rostro_156.jpg', 'rostro_157.jpg', 'rostro_158.jpg', 'rostro_159.jpg', 'rostro_16.jpg', 'rostro_160.jpg', 'rostro_161.jpg', 'rostro_162.jpg', 'rostro_163.jpg', 'rostro_164.jpg', 'rostro_165.jpg', 'rostro_166.jpg', 'rostro_167.jpg', 'rostro_168.jpg', 'rostro_169.jpg', 'rostro_17.jpg', 'rostro_170.jpg', 'rostro_171.jpg', 'rostro_172.jpg', 'rostro_173.jpg', 'rostro_174.jpg', 'rostro_175.jpg', 'rostro_176.jpg', 'rostro_177.jpg', 'rostro_178.jpg', 'rostro_179.jpg', 'rostro_18.jpg', 'rostro_180.jpg', 'rostro_181.jpg', 'rostro_182.jpg', 'rostro_183.jpg', 'rostro_184.jpg', 'rostro_185.jpg', 'rostro_186.jpg', 'rostro_187.jpg', 'rostro_188.jpg', 'rostro_189.jpg', 'rostro_19.jpg', 'rostro_190.jpg', 'rostro_191.jpg', 'rostro_192.jpg', 'rostro_193.jpg', 'rostro_194.jpg', 'rostro_195.jpg', 'rostro_196.jpg', 'rostro_197.jpg', 'rostro_198.jpg', 'rostro_199.jpg', 'rostro_2.jpg', 'rostro_20.jpg', 'rostro_200.jpg', 'rostro_21.jpg', 'rostro_22.jpg', 'rostro_23.jpg', 'rostro_24.jpg', 'rostro_25.jpg', 'rostro_26.jpg', 'rostro_27.jpg', 'rostro_28.jpg', 'rostro_29.jpg', 'rostro_3.jpg', 'rostro_30.jpg', 'rostro_31.jpg', 'rostro_32.jpg', 'rostro_33.jpg', 'rostro_34.jpg', 'rostro_35.jpg', 'rostro_36.jpg', 'rostro_37.jpg', 'rostro_38.jpg', 'rostro_39.jpg', 'rostro_4.jpg', 'rostro_40.jpg', 'rostro_41.jpg', 'rostro_42.jpg', 'rostro_43.jpg', 'rostro_44.jpg', 'rostro_45.jpg', 'rostro_46.jpg', 'rostro_47.jpg', 'rostro_48.jpg', 'rostro_49.jpg', 'rostro_5.jpg', 'rostro_50.jpg', 'rostro_51.jpg', 'rostro_52.jpg', 'rostro_53.jpg', 'rostro_54.jpg', 'rostro_55.jpg', 'rostro_56.jpg', 'rostro_57.jpg', 'rostro_58.jpg', 'rostro_59.jpg', 'rostro_6.jpg', 'rostro_60.jpg', 'rostro_61.jpg', 'rostro_62.jpg', 'rostro_63.jpg', 'rostro_64.jpg', 'rostro_65.jpg', 'rostro_66.jpg', 'rostro_67.jpg', 'rostro_68.jpg', 'rostro_69.jpg', 'rostro_7.jpg', 'rostro_70.jpg', 'rostro_71.jpg', 'rostro_72.jpg', 'rostro_73.jpg', 'rostro_74.jpg', 'rostro_75.jpg', 'rostro_76.jpg', 'rostro_77.jpg', 'rostro_78.jpg', 'rostro_79.jpg', 'rostro_8.jpg', 'rostro_80.jpg', 'rostro_81.jpg', 'rostro_82.jpg', 'rostro_83.jpg', 'rostro_84.jpg', 'rostro_85.jpg', 'rostro_86.jpg', 'rostro_87.jpg', 'rostro_88.jpg', 'rostro_89.jpg', 'rostro_9.jpg', 'rostro_90.jpg', 'rostro_91.jpg', 'rostro_92.jpg', 'rostro_93.jpg', 'rostro_94.jpg', 'rostro_95.jpg', 'rostro_96.jpg', 'rostro_97.jpg', 'rostro_98.jpg', 'rostro_99.jpg', 'samuel', 'yoana']\n",
      "Cargando imágenes de: marcelo (Etiqueta: 0)\n",
      "Cargando imágenes de: samuel (Etiqueta: 1)\n",
      "Cargando imágenes de: yoana (Etiqueta: 2)\n",
      "Total de imágenes cargadas: 602\n",
      "Entrenando modelo LBPH...\n",
      "Modelo LBPH almacenado correctamente.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Ruta donde están almacenadas las carpetas de usuarios\n",
    "dataPath = \"Rostros\"  \n",
    "userFolders = os.listdir(dataPath)  # Lista de carpetas de usuarios\n",
    "print(f\"Usuarios encontrados: {userFolders}\")\n",
    "\n",
    "# Listas para almacenar los datos y etiquetas\n",
    "facesData = []\n",
    "labels = []\n",
    "label = 0  # Etiqueta inicial\n",
    "\n",
    "# Recorrer cada carpeta de usuario\n",
    "for user in userFolders:\n",
    "    userPath = os.path.join(dataPath, user)  \n",
    "    \n",
    "    if os.path.isdir(userPath):  # Verificar que sea un directorio\n",
    "        imageFiles = os.listdir(userPath)  # Lista de imágenes en la carpeta del usuario\n",
    "        \n",
    "        print(f\"Cargando imágenes de: {user} (Etiqueta: {label})\")\n",
    "\n",
    "        for fileName in imageFiles:\n",
    "            filePath = os.path.join(userPath, fileName)\n",
    "            \n",
    "            # Verificar que el archivo sea una imagen\n",
    "            if fileName.endswith(\".jpg\") or fileName.endswith(\".png\"):\n",
    "                image = cv2.imread(filePath, cv2.IMREAD_GRAYSCALE)  # Leer en escala de grises\n",
    "\n",
    "                facesData.append(image)\n",
    "                labels.append(label)  # Asignar etiqueta única a cada usuario\n",
    "\n",
    "        label += 1  # Incrementar etiqueta para el siguiente usuario\n",
    "\n",
    "print(f\"Total de imágenes cargadas: {len(facesData)}\")\n",
    "\n",
    "# Crear el modelo LBPH\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Entrenar el modelo con las imágenes y etiquetas\n",
    "print(\"Entrenando modelo LBPH...\")\n",
    "face_recognizer.train(facesData, np.array(labels))\n",
    "\n",
    "# Guardar el modelo entrenado para pruebas futuras\n",
    "face_recognizer.write('modeloLBPHFace.xml')\n",
    "print(\"Modelo LBPH almacenado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ae9c7-9610-4322-af60-028262acaf85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
